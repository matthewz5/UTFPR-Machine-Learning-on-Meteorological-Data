{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Introduction**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research for the statistical analysis of meteorological data and machine learning methods for determining solar irradiation.\n",
    "\n",
    "Researcher: Matheus Henrique da Silva.\n",
    "Control and Automation Engineering Student.\n",
    "Universidade Tecnológica Federal do Paraná, Cornélio Procópio, Paraná, Brasil. \n",
    "E-mail: matheussilva.2019@alunos.utfpr.edu.br. \n",
    "ID Lattes: 5450995625966991.\n",
    "\n",
    "Supervisor: Wesley Angelino de Souza.\n",
    "Lecturer in the Graduate Program in Electrical Engineering.\n",
    "Universidade Tecnológica Federal do Paraná, Cornélio Procópio, Paraná, Brasil. \n",
    "E-mail: wesleyangelino@utfpr.edu.br. \n",
    "ID Lattes: 8594457321079718.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of these code file\n",
    "\n",
    "- Step 0 - Importing Libraries;\n",
    "- Step 1 - data extraction and agglutination;\n",
    "- Step 2 - statistical and exploratory analysis;\n",
    "- Step 3 - data normalization and division;\n",
    "- Step 4 - Machine Learning models training;\n",
    "- Step 5 - Variables selection to optimize the ML models;\n",
    "- Step 6 - Optimization of parameters of ML models;\n",
    "- Step 7 - Cross validation of ML models optmize;\n",
    "- Step 8 - Application of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 0 - Importing Libraries**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# Grapichs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "# For warnings\n",
    "pd.options.mode.chained_assignment = None  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 1 - data extraction and agglutination**\n",
    "\n",
    "---\n",
    "\n",
    "Data collected and made available by the Instituto Nacional de Meteorologia (INMET), acess on https://portal.inmet.gov.br/, in format .csv of 606 meteorological collection stations of Brazil between 2010 and 2021.\n",
    "\n",
    "Each .csv file contains 9 lines with information about the station: Nome; Codigo Estacao; Latitude; Longitude; Altitude; Situacao; Data Inicial; Data Final e Periodicidade da Medicao.\n",
    "\n",
    "In line 11, contains the name of the variables: Data Medicao; Hora Medicao; PRECIPITACAO TOTAL, HORARIO(mm); PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA(mB); PRESSAO ATMOSFERICA REDUZIDA NIVEL DO MAR, AUT(mB); PRESSAO ATMOSFERICA MAX.NA HORA ANT. (AUT)(mB); PRESSAO ATMOSFERICA MIN. NA HORA ANT. (AUT)(mB); RADIACAO GLOBAL(Kj/mÂ²); TEMPERATURA DA CPU DA ESTACAO(Â°C); TEMPERATURA DO AR - BULBO SECO, HORARIA(Â°C); TEMPERATURA DO PONTO DE ORVALHO(Â°C); TEMPERATURA MAXIMA NA HORA ANT. (AUT)(Â°C); TEMPERATURA MINIMA NA HORA ANT. (AUT)(Â°C); TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT)(Â°C); TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT)(Â°C); TENSAO DA BATERIA DA ESTACAO(V); UMIDADE REL. MAX. NA HORA ANT. (AUT)(%); UMIDADE REL. MIN. NA HORA ANT. (AUT)(%); UMIDADE RELATIVA DO AR, HORARIA(%); VENTO, DIRECAO HORARIA (gr)(Â° (gr)); VENTO, RAJADA MAXIMA(m/s); VENTO, VELOCIDADE HORARIA(m/s).\n",
    "\n",
    "From line 12, the data collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the informations of all stations\n",
    "\n",
    "df_stations = pd.DataFrame(columns =  [\"csv\", \"nome\", \"codigo\", \"latitude\", \n",
    "                                       \"longitude\", \"altitude\", \"situacao\", \"data_inicio\", \n",
    "                                       \"data_fim\", \"periodicidade\"])\n",
    "\n",
    "for file in glob.glob(\"all_data/*.csv\"):\n",
    "        \n",
    "    arquivo = file\n",
    "    file = open(file)\n",
    "\n",
    "    csv_reader = csv.reader(file)\n",
    "\n",
    "    # 1: 'nome': nome_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    nome_estacao = tmp[1]\n",
    "    \n",
    "    # 2: 'codigo': codigo_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    codigo_estacao = tmp[1]\n",
    "    \n",
    "    # 3: 'latitude': latitude_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    latitude_estacao = tmp[1]\n",
    "    \n",
    "    # 4: 'longitude': longitude_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    longitude_estacao = tmp[1]\n",
    "    \n",
    "    # 5: 'altitude': altitude_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    altitude_estacao = tmp[1]\n",
    "    \n",
    "    # 5: 'situacao': situacao_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    situacao_estacao = tmp[1]\n",
    "    \n",
    "    # 6: 'data_inicio': data_inicio_coleta_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    data_inicio_coleta_estacao = tmp[1]\n",
    "    \n",
    "    # 7: 'data_fim': data_fim_coleta_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    data_fim_coleta_estacao = tmp[1]\n",
    "\n",
    "    # 8: 'periodicidade': peridiocidade_dados_estacao\n",
    "    row = next(csv_reader)\n",
    "    row=str(row[0])\n",
    "    tmp=row.split(\": \")\n",
    "    peridiocidade_dados_estacao = tmp[1]\n",
    "    \n",
    "    new_row = {'csv': str(arquivo), \n",
    "               'nome': nome_estacao, \n",
    "               'codigo': codigo_estacao, \n",
    "               'latitude': latitude_estacao,\n",
    "               'longitude': longitude_estacao,\n",
    "               'altitude': altitude_estacao,\n",
    "               'situacao': situacao_estacao, \n",
    "               'data_inicio': data_inicio_coleta_estacao, \n",
    "               'data_fim': data_fim_coleta_estacao, \n",
    "               'periodicidade': peridiocidade_dados_estacao}\n",
    "    \n",
    "    df_stations = df_stations.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification of data types and changes for station selection\n",
    "\n",
    "data_types = df_stations.dtypes\n",
    "\n",
    "print(data_types)\n",
    "\n",
    "df_stations['latitude'] = df_stations['latitude'].astype(float)\n",
    "df_stations['longitude'] = df_stations['longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of the stations in Cornélio Procópio-PR region\n",
    "\n",
    "lat = -23.185038698153438\n",
    "lon = -50.647548006591066\n",
    "dist = 4\n",
    "\n",
    "lim_lat_higher = lat + dist \n",
    "lim_lat_bottom = lat - dist\n",
    "\n",
    "lim_lon_right = lon + dist\n",
    "lim_lon_left = lon - dist\n",
    "\n",
    "selected_stations = df_stations[((df_stations['latitude'] >= lim_lat_bottom) & (df_stations['latitude'] <= lim_lat_higher)) & \\\n",
    "                            ((df_stations['longitude'] >= lim_lon_left) & (df_stations['longitude'] <= lim_lon_right))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic map for station location\n",
    "\n",
    "map = folium.Map(location=[lat, lon], zoom_start=14)\n",
    "\n",
    "folium.Marker(location=[lat, lon], popup='CORNÉLIO PROCÓPIO').add_to(map)\n",
    "\n",
    "lenght = selected_stations.shape[0]\n",
    "\n",
    "lat_ar = np.zeros(lenght)\n",
    "lon_ar = np.zeros(lenght)\n",
    "est_ar = np.empty((lenght), dtype=object)\n",
    "\n",
    "index = selected_stations.index.to_numpy()\n",
    "\n",
    "for i in range(lenght):\n",
    "\n",
    "    lat_ar[i] = selected_stations.loc[index[i], 'latitude']\n",
    "    lon_ar[i] = selected_stations.loc[index[i], 'longitude']\n",
    "    est_ar[i] = selected_stations.loc[index[i], 'nome']\n",
    "\n",
    "    popup_station = folium.Popup(f'{est_ar[i]}\\n{lat_ar[i]},{lon_ar[i]}')\n",
    "    folium.Marker(location=[lat_ar[i], lon_ar[i]], popup=popup_station).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the data agglutination\n",
    "\n",
    "data_loaded = 1\n",
    "\n",
    "if(data_loaded==0):\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for file in selected_stations['csv']:\n",
    "\n",
    "        df_temp = pd.read_csv(file, skiprows=10, delimiter=\";\", decimal=\",\")\n",
    "        df_temp.drop(df_temp.columns[[4,5,6,8,11,12,13,14,15,16,17,22]],axis=1, inplace = True)\n",
    "        df_temp.dropna(inplace=True)\n",
    "\n",
    "        result = pd.concat([result, df_temp])\n",
    "        \n",
    "    result.to_csv('data_agglutinated/data_selected_stations.csv') \n",
    "    \n",
    "else:\n",
    "    result = pd.read_csv('data_agglutinated/data_selected_stations.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 2 - statistical and exploratory analysis**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.1 - load and transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv('data_agglutinated/data_selected_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change variables name and format of date\n",
    "\n",
    "data.drop(data.columns[0],axis=1, inplace = True)\n",
    "data.rename(columns = {'Data Medicao': 'data'}, inplace = True)\n",
    "data['data'] = pd.to_datetime(data['data'])\n",
    "data.rename(columns = {'Hora Medicao': 'hora'}, inplace = True)\n",
    "data.rename(columns = {'PRECIPITACAO TOTAL, HORARIO(mm)': 'precipitacao'}, inplace = True)\n",
    "data.rename(columns = {'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA(mB)': 'pressao_atm'}, inplace = True)\n",
    "data.rename(columns = {'RADIACAO GLOBAL(Kj/m²)': 'radiacao'}, inplace = True)\n",
    "data.rename(columns = {'TEMPERATURA DO AR - BULBO SECO, HORARIA(°C)': 'temperatura'}, inplace = True)\n",
    "data.rename(columns = {'TEMPERATURA DO PONTO DE ORVALHO(°C)': 'temp_orvalho'}, inplace = True)\n",
    "data.rename(columns = {'UMIDADE RELATIVA DO AR, HORARIA(%)': 'umidade'}, inplace = True)\n",
    "data.rename(columns = {'VENTO, DIRECAO HORARIA (gr)(° (gr))': 'direcao_vento'}, inplace = True)\n",
    "data.rename(columns = {'VENTO, RAJADA MAXIMA(m/s)': 'vento_maximo'}, inplace = True)\n",
    "data.rename(columns = {'VENTO, VELOCIDADE HORARIA(m/s)': 'velocidade'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of target variable 'radiacao' by 'hora'\n",
    "\n",
    "ax = data.plot(kind=\"scatter\", x=\"hora\", y=\"radiacao\", alpha=0.1)\n",
    "ax.tick_params(axis='both', which='both', labelsize=14)\n",
    "ax.set_xlabel(\"hora\", fontsize=14)\n",
    "ax.set_ylabel(\"irradiacao\", fontsize=14) \n",
    "\n",
    "plt.savefig('figures/scatter_radiacao_hora.png', format='png', dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preliminary analyses, we noticed that the data are concentrated between 10 am and 10 pm\n",
    "\n",
    "However, solar radiation begins to be noticed along with sunrise ~ 6:40 am\n",
    "\n",
    "Therefore, we will shift the data by -3 hours each (due to the Brazilian time zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_hour(df):\n",
    "\n",
    "    df['hora'] = df['hora'].replace(0, 21)\n",
    "    df['hora'] = df['hora'].replace(100, 22)\n",
    "    df['hora'] = df['hora'].replace(200, 23)\n",
    "    df['hora'] = df['hora'].replace(300, 0)\n",
    "    df['hora'] = df['hora'].replace(400, 1)\n",
    "    df['hora'] = df['hora'].replace(500, 2)\n",
    "    df['hora'] = df['hora'].replace(600, 3)\n",
    "    df['hora'] = df['hora'].replace(700, 4)\n",
    "    df['hora'] = df['hora'].replace(800, 5)\n",
    "    df['hora'] = df['hora'].replace(900, 6)\n",
    "    df['hora'] = df['hora'].replace(1000, 7)\n",
    "    df['hora'] = df['hora'].replace(1100, 8)\n",
    "    df['hora'] = df['hora'].replace(1200, 9)\n",
    "    df['hora'] = df['hora'].replace(1300, 10)\n",
    "    df['hora'] = df['hora'].replace(1400, 11)\n",
    "    df['hora'] = df['hora'].replace(1500, 12)\n",
    "    df['hora'] = df['hora'].replace(1600, 13)\n",
    "    df['hora'] = df['hora'].replace(1700, 14)\n",
    "    df['hora'] = df['hora'].replace(1800, 15)\n",
    "    df['hora'] = df['hora'].replace(1900, 16)\n",
    "    df['hora'] = df['hora'].replace(2000, 17)\n",
    "    df['hora'] = df['hora'].replace(2100, 18)\n",
    "    df['hora'] = df['hora'].replace(2200, 19)\n",
    "    df['hora'] = df['hora'].replace(2300, 20)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adjust_hour(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dataframe info, quantities and types\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NULL values\n",
    "\n",
    "non_null_counts = data.count()\n",
    "\n",
    "print(non_null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical describe\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2 - data cleaning\n",
    "\n",
    "Previously, there were discrepant values ​​noticed at unconventional times, for this reason they caused the outliers to be cleaned in a different way:\n",
    "\n",
    "We take the data per hour, and remove according to the variable_target 'radiacao' the last 3.5 * standard deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_out(df):\n",
    "\n",
    "    dados_0 = df[df['hora'] == 0]\n",
    "    dados_1 = df[df['hora'] == 1]\n",
    "    dados_2 = df[df['hora'] == 2]\n",
    "    dados_3 = df[df['hora'] == 3]\n",
    "    dados_4 = df[df['hora'] == 4]\n",
    "    dados_5 = df[df['hora'] == 5]\n",
    "    dados_6 = df[df['hora'] == 6]\n",
    "    dados_7 = df[df['hora'] == 7]\n",
    "    dados_8 = df[df['hora'] == 8]\n",
    "    dados_9 = df[df['hora'] == 9]\n",
    "    dados_10 = df[df['hora'] == 10]\n",
    "    dados_11 = df[df['hora'] == 11]\n",
    "    dados_12 = df[df['hora'] == 12]\n",
    "    dados_13 = df[df['hora'] == 13]\n",
    "    dados_14 = df[df['hora'] == 14]\n",
    "    dados_15 = df[df['hora'] == 15]\n",
    "    dados_16 = df[df['hora'] == 16]\n",
    "    dados_17 = df[df['hora'] == 17]\n",
    "    dados_18 = df[df['hora'] == 18]\n",
    "    dados_19 = df[df['hora'] == 19]\n",
    "    dados_20 = df[df['hora'] == 20]\n",
    "    dados_21 = df[df['hora'] == 21]\n",
    "    dados_22 = df[df['hora'] == 22]\n",
    "    dados_23 = df[df['hora'] == 23]\n",
    "\n",
    "    data_hour = [dados_0, dados_1, dados_2, dados_3, dados_4, dados_5, dados_6, dados_7, dados_8, dados_9, dados_10, dados_11, dados_12, dados_13, dados_14, dados_15, dados_16, dados_17, dados_18, dados_19, dados_20, dados_21, dados_22, dados_23]\n",
    "\n",
    "    data_filtered = pd.DataFrame()\n",
    "\n",
    "    for i in data_hour:\n",
    "\n",
    "        mean_radiacao = np.mean(i['radiacao'])\n",
    "        std_radiacao = np.std(i['radiacao'])\n",
    "\n",
    "        lower = mean_radiacao - 3.5 * std_radiacao\n",
    "        upper = mean_radiacao + 3.5 * std_radiacao\n",
    "\n",
    "        y = i.query('radiacao <= @upper')\n",
    "\n",
    "        data_filtered = pd.concat([data_filtered, y])\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_out(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of target variable 'radiacao' by 'hora' with filtered data\n",
    "\n",
    "data.plot(kind=\"scatter\", x=\"hora\", y=\"radiacao\", alpha=0.1)\n",
    "ax.tick_params(axis='both', which='both', labelsize=14)\n",
    "ax.set_xlabel(\"hora\", fontsize=14)\n",
    "ax.set_ylabel(\"irradiacao\", fontsize=14) \n",
    "\n",
    "plt.savefig('figures/scatter_radiacao_hora_filtered.png', format='png', dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3 - statistical analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical describe with filtered data\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the variables\n",
    "\n",
    "def histogram_variables(df, filename=None):\n",
    "\n",
    "    df.hist(bins=50, figsize=(20,15))\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_variables(data, 'figures/histogram_variables.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of the target variable 'radiacao' with all variables\n",
    "\n",
    "def scatter_variables(df, variable, filename=None):\n",
    "\n",
    "    variables = df.columns.drop(variable)\n",
    "\n",
    "    data = df[[variable] + list(variables)]\n",
    "\n",
    "    sns.pairplot(data, x_vars=variables, y_vars=variable, height=2.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=500, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_variables(data, 'radiacao', 'figures/scatter_variables.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness values\n",
    "\n",
    "data.skew(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation\n",
    "\n",
    "def pearson_correlation_map(df, filename=None):\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "\n",
    "    sns.heatmap(df.corr(), annot = True, fmt = '.4f', cmap = 'Reds', vmax = .99, vmin = -0.60)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation plot\n",
    "\n",
    "pearson_correlation_map(data, 'figures/pearson_correlation_map.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multicollinearity problem\n",
    "\n",
    "df_correlation = data.corr()\n",
    "\n",
    "df_correlation = df_correlation[((df_correlation >= .65) | (df_correlation <= -.65)) & (df_correlation !=1.000)]\n",
    "df_correlation = df_correlation.drop('radiacao', axis=1)\n",
    "df_correlation = df_correlation.drop('radiacao', axis=0)\n",
    "\n",
    "df_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is a high correlation between 'vento_maximo' and 'velocidade' \n",
    "# let's remove 'velocidade' from the analysis, because it has the lowest correlation with 'radiacao'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 3 - data normalization and division**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3.1 - normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StardartScaler\n",
    "\n",
    "def norm_std(df, variables):\n",
    "\n",
    "    scaler_lab = StandardScaler()\n",
    "    scaler_lab.fit(df[variables])\n",
    "    scaled_features_lab = scaler_lab.transform(df[variables])\n",
    "\n",
    "    data_std = pd.DataFrame(scaled_features_lab, columns = variables, index = df.index)\n",
    "\n",
    "    return data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "def norm_minmax(df, variables):\n",
    "\n",
    "    data_minmax = df.copy()\n",
    "\n",
    "    scaler_lab = MinMaxScaler()\n",
    "\n",
    "    data_minmax[variables] = scaler_lab.fit_transform(data_minmax[variables])\n",
    "\n",
    "    return data_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data backup, with the variable 'data'\n",
    "\n",
    "backup_data = pd.DataFrame({'radiacao': data['radiacao'],\n",
    "                            'data': data['data'],\n",
    "                            'hora': data['hora'],\n",
    "                            'precipitacao': data['precipitacao'],\n",
    "                            'pressao_atm': data['pressao_atm'],\n",
    "                            'temperatura': data['temperatura'],\n",
    "                            'temp_orvalho': data['temp_orvalho'],\n",
    "                            'umidade': data['umidade'],\n",
    "                            'direcao_vento': data['direcao_vento'],\n",
    "                            'vento_maximo': data['vento_maximo']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe wiithou the variable 'data' beacause we keep this to the future steps of testins\n",
    "\n",
    "data2 = pd.DataFrame({'radiacao': data['radiacao'],\n",
    "                    'hora': data['hora'],\n",
    "                    'precipitacao': data['precipitacao'],\n",
    "                    'pressao_atm': data['pressao_atm'],\n",
    "                    'temperatura': data['temperatura'],\n",
    "                    'temp_orvalho': data['temp_orvalho'],\n",
    "                    'umidade': data['umidade'],\n",
    "                    'direcao_vento': data['direcao_vento'],\n",
    "                    'vento_maximo': data['vento_maximo']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables list\n",
    "\n",
    "variables = ['radiacao', 'hora', 'precipitacao', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot figure to the variables of the data\n",
    "\n",
    "def boxplots_variables(df, filename=None):\n",
    "\n",
    "    melted_df = df.melt(value_vars=df, var_name='Variable', value_name='Values')\n",
    "\n",
    "    sns.catplot(data=melted_df, x='Variable', y='Values', kind='box', height=8, aspect=1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=500, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD normalization and bloxplot\n",
    "\n",
    "data_std = norm_std(data2, variables)\n",
    "\n",
    "boxplots_variables(data_std, 'figures/bloxplot_data_std.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX normalization and boxplot\n",
    "\n",
    "data_minmax = norm_minmax(data2, variables)\n",
    "\n",
    "boxplots_variables(data_minmax, 'figures/bloxplot_data_minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3.2 - data division\n",
    "\n",
    "70% -> train\n",
    "\n",
    "20% -> test\n",
    "\n",
    "10% -> validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_divide(df):\n",
    "\n",
    "    X = df[['hora', 'precipitacao', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']].values\n",
    "    y = df.radiacao.values.reshape(-1,1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.125, random_state=42)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandartScaler\n",
    "\n",
    "x_train_std, y_train_std, x_test_std, y_test_std, x_valid_std, y_valid_std = data_divide(data_std)\n",
    "\n",
    "# Checking division\n",
    "\n",
    "print('train 70% =', len(y_train_std))\n",
    "print('test 20%  =', len(y_test_std))\n",
    "print('validation 10% =', len(y_valid_std))\n",
    "\n",
    "print(len(data_std), '=', len(y_train_std)+len(y_test_std)+len(y_valid_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "x_train_minmax, y_train_minmax, x_test_minmax, y_test_minmax, x_valid_minmax, y_valid_minmax = data_divide(data_minmax)\n",
    "\n",
    "# Checking division\n",
    "\n",
    "print('train 70% =', len(y_train_minmax))\n",
    "print('test 20%  =', len(y_test_minmax))\n",
    "print('validation 10% =', len(y_valid_minmax))\n",
    "\n",
    "print(len(data_std), '=', len(y_train_minmax)+len(y_test_minmax)+len(y_valid_minmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 4 - Machine Learning models training**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing, error calculator and dataframe function\n",
    "\n",
    "def model_test(model, x_test, y_test):\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    R2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "    print('-'*60)\n",
    "    print('Mean Absolute Error:', MAE)\n",
    "    print('Mean Squared Error:', MSE)\n",
    "    print('Root Mean Squared Error:', RMSE)\n",
    "    print('R2 Score:', R2)\n",
    "\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    df_determined = pd.DataFrame({'measured_rad': y_test.flatten(), 'determined_rad': y_pred.flatten()})\n",
    "\n",
    "    print('-'*60)\n",
    "    print(df_determined)\n",
    "    print('-'*60)\n",
    "\n",
    "    return df_determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1 - Multilayer Perceptron Regressor (MLPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def model_mlpr(x_train, y_train):\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_std = 0\n",
    "\n",
    "if control_mlpr_std == 1:\n",
    "\n",
    "    model_mlpr_std = model_mlpr(x_train_std, y_train_std)\n",
    "\n",
    "    joblib.dump(model_mlpr_std, 'ml_models/model_mlpr_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_std_test = 0\n",
    "\n",
    "if control_mlpr_std_test == 1:\n",
    "\n",
    "    df_determined_mlpr_std = model_test(model_mlpr_std, x_test_std, y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_minmax = 0\n",
    "\n",
    "if control_mlpr_minmax == 1:\n",
    "\n",
    "    model_mlpr_minmax = model_mlpr(x_train_minmax, y_train_minmax)\n",
    "\n",
    "    joblib.dump(model_mlpr_minmax, 'ml_models/modelo_mlpr_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_minmax_test = 0\n",
    "\n",
    "if control_mlpr_minmax_test == 1:\n",
    "\n",
    "    df_determined_mlpr_minmax = model_test(model_mlpr_minmax, x_test_minmax, y_test_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.2 - Decision Tree Regressor (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def model_dtr(x_train, y_train):\n",
    "\n",
    "    model = DecisionTreeRegressor(max_depth=100, min_samples_leaf=2, random_state = 42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_std = 0\n",
    "\n",
    "if control_dtr_std == 1:\n",
    "\n",
    "    model_dtr_std = model_dtr(x_train_std, y_train_std)\n",
    "    \n",
    "    joblib.dump(model_dtr_std, 'ml_models/model_dtr_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_std_test = 0\n",
    "\n",
    "if control_dtr_std_test == 1:\n",
    "    \n",
    "    df_determined_dtr_std = model_test(model_dtr_std, x_test_std, y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_minmax = 0\n",
    "\n",
    "if control_dtr_minmax == 1:\n",
    "\n",
    "    model_dtr_minmax = model_dtr(x_train_minmax, y_train_minmax)\n",
    "    \n",
    "    joblib.dump(model_dtr_minmax, 'ml_models/model_dtr_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_minmax_test = 0\n",
    "\n",
    "if control_dtr_minmax_test == 1:\n",
    "\n",
    "    df_determined_dtr_minmax = model_test(model_dtr_minmax, x_test_minmax, y_test_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.3 - Random Forest Regressor (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def model_rfr(x_train, y_train):\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=50, min_samples_leaf=2, random_state = 42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_std = 0\n",
    "\n",
    "if control_rfr_std == 1:\n",
    "\n",
    "    model_rfr_std = model_rfr(x_train_std, y_train_std)\n",
    "    \n",
    "    joblib.dump(model_rfr_std, 'ml_models/model_rfr_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_std_test = 0\n",
    "\n",
    "if control_rfr_std_test == 1:\n",
    "    \n",
    "    df_determined_rfr_std = model_test(model_rfr_std, x_test_std, y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_minmax = 1\n",
    "\n",
    "if control_rfr_minmax == 1:\n",
    "\n",
    "    model_rfr_minmax = model_rfr(x_train_minmax, y_train_minmax)\n",
    "\n",
    "    joblib.dump(control_rfr_minmax, 'ml_models/model_rfr_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_minmax_test = 1\n",
    "\n",
    "if control_rfr_minmax_test == 1:\n",
    "\n",
    "    df_determined_rfr_minmax = model_test(model_rfr_minmax, x_test_minmax, y_test_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.4 - K Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def model_knn(x_train, y_train):\n",
    "\n",
    "    model = KNeighborsRegressor(n_neighbors=3, leaf_size=30, weights='distance', algorithm='auto', metric='euclidean')\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_std = 0\n",
    "\n",
    "if control_knn_std == 1:\n",
    "\n",
    "    model_knn_std = model_knn(x_train_std, y_train_std)\n",
    "    \n",
    "    joblib.dump(model_knn_std, 'ml_models/model_knn_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_std_test = 0\n",
    "\n",
    "if control_knn_std_test == 1:\n",
    "    \n",
    "    df_determined_knn_std = model_test(model_knn_std, x_test_std, y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_minmax = 0\n",
    "\n",
    "if control_knn_minmax == 1:\n",
    "\n",
    "    model_knn_minmax = model_knn(x_train_minmax, y_train_minmax)\n",
    "\n",
    "    joblib.dump(model_knn_minmax, 'ml_models/model_knn_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_minmax_test = 0\n",
    "\n",
    "if control_knn_minmax_test == 1:\n",
    "\n",
    "    df_determined_knn_minmax = model_test(model_knn_minmax, x_test_minmax, y_test_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.5 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "# ====================================================================================================================== #\n",
    "# | ML with data STD normalization                             | | ML with data MINMAX normalization                   | #\n",
    "# ====================================================================================================================== #\n",
    "#                                                                                                                        #\n",
    "# MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)                          #\n",
    "# DecisionTreeRegressor(max_depth=100, min_samples_leaf=2, random_state = 42)                                            #\n",
    "# RandomForestRegressor(n_estimators=100, max_depth=50, min_samples_leaf=2, random_state = 42)                           #\n",
    "# KNeighborsRegressor(n_neighbors=3, leaf_size=30, weights='distance', algorithm='auto', metric='euclidean')             #\n",
    "#                                                                                                                        #\n",
    "# ====================================================================================================================== #\n",
    "# |      |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MAE  |                 | 0.1767 | 0.2282 | 0.1692 | 0.1999 | |                 | 0.0319 | 0.0410 | 0.0304 | 0.0344 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MSE  |                 | 0.1109 | 0.2035 | 0.1111 | 0.1489 | |                 | 0.0036 | 0.0065 | 0.0035 | 0.0046 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | RMSE |                 | 0.3331 | 0.4512 | 0.3334 | 0.3859 | |                 | 0.0605 | 0.0811 | 0.0599 | 0.0677 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | R2   |                 | 0.8889 | 0.7963 | 0.8887 | 0.8510 | |                 | 0.8865 | 0.7962 | 0.8887 | 0.8580 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttrn |                 | 11m28s | 48.3s  | 61m45s | 19,3s  | |                 | 13m38s | 44.7s  | 61m40s | 16,7s  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttst |                 | 18.3s  | 1.0s   | 3m4s   | 5m33s  | |                 | 5s     | 1.0s   | 4m3.6s | 4m17s  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 5 - Variables selection to optimize the ML models**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5.1 - Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD\n",
    "\n",
    "model_mlpr_std = joblib.load('ml_models/model_mlpr_std.pkl')\n",
    "model_dtr_std = joblib.load('ml_models/model_dtr_std.pkl')\n",
    "model_rfr_std = joblib.load('ml_models/model_rfr_std.pkl')\n",
    "model_knn_std = joblib.load('ml_models/model_knn_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX\n",
    "\n",
    "model_mlpr_minmax = joblib.load('ml_models/model_mlpr_minmax.pkl')\n",
    "model_dtr_minmax = joblib.load('ml_models/model_dtr_minmax.pkl')\n",
    "model_rfr_minmax = joblib.load('ml_models/model_rfr_minmax.pkl')\n",
    "model_knn_minmax = joblib.load('ml_models/model_knn_minmax.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5.2 - Filter - Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe without the 'radiacao'\n",
    "\n",
    "data_std_pi = data_std.copy()\n",
    "data_std_pi.drop(data_std.columns[0],axis=1, inplace=True)\n",
    "\n",
    "data_minmax_pi = data_minmax.copy()\n",
    "data_minmax_pi.drop(data_minmax.columns[0],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_imp(data_x, model, x_train, y_train, filename=None):\n",
    "\n",
    "    importance = permutation_importance(model, x_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "    importance_mean = importance.importances_mean\n",
    "\n",
    "    name_variables = data_x.columns\n",
    "\n",
    "    print(name_variables)\n",
    "\n",
    "    df_importance = pd.DataFrame({'Variables': name_variables, 'Importance': importance_mean})\n",
    "\n",
    "    df_importance = df_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.barh(df_importance['Variables'], df_importance['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Predictor Variables')\n",
    "    plt.title(f'Importance no {model}')\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Regressor (MLPR)\n",
    "\n",
    "controle_pi_mlpr = 0\n",
    "\n",
    "if controle_pi_mlpr == 1:\n",
    "\n",
    "    perm_imp(data_std_pi, model_mlpr_std, x_train_std, y_train_std, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor (DTR)\n",
    "\n",
    "controle_pi_dtr = 0\n",
    "\n",
    "if controle_pi_dtr == 1:\n",
    "\n",
    "    perm_imp(data_std_pi, model_dtr_std, x_train_std, y_train_std, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor (RFR)\n",
    "\n",
    "controle_pi_rfr = 0\n",
    "\n",
    "if controle_pi_rfr == 1:\n",
    "\n",
    "    perm_imp(data_std_pi, model_rfr_std, x_train_std, y_train_std, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Regressor (KNN)\n",
    "\n",
    "controle_pi_knn = 0\n",
    "\n",
    "if controle_pi_knn == 1:\n",
    "\n",
    "    perm_imp(data_std_pi, model_knn_std, x_train_std, y_train_std, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5.3 - Preparing Dataframes for training and testing models with Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Regressor (MLPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mlpr_pi = pd.DataFrame({'radiacao': data2['radiacao'],\n",
    "                            'hora': data2['hora'],\n",
    "                            'temperatura': data2['temperatura'],\n",
    "                            'umidade': data2['umidade']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_mlpr_pi = ['radiacao', 'hora', 'temperatura', 'umidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mlpr_pi_std = norm_std(data_mlpr_pi, variables_mlpr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mlpr_pi_std, y_train_mlpr_pi_std, x_test_mlpr_pi_std, y_test_mlpr_pi_std, x_valid_mlpr_pi_std, y_valid_mlpr_pi_std = data_divide(data_mlpr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mlpr_pi_minmax = norm_minmax(data_mlpr_pi, variables_mlpr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mlpr_pi_minmax, y_train_mlpr_pi_minmax, x_test_mlpr_pi_minmax, y_test_mlpr_pi_minmax, x_valid_mlpr_pi_minmax, y_valid_mlpr_pi_minmax = data_divide(data_mlpr_pi_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtr_pi = pd.DataFrame({'radiacao': data2['radiacao'],\n",
    "                            'hora': data2['hora'],\n",
    "                            'pressao_atm': data2['pressao_atm'],\n",
    "                            'temperatura': data2['temperatura'],\n",
    "                            'temp_orvalho': data2['temp_orvalho'],\n",
    "                            'umidade': data2['umidade'],\n",
    "                            'direcao_vento': data2['direcao_vento'],\n",
    "                            'vento_maximo': data2['vento_maximo']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_dtr_pi = ['radiacao', 'hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtr_pi_std = norm_std(data_dtr_pi, variables_dtr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtr_pi_std, y_train_dtr_pi_std, x_test_dtr_pi_std, y_test_dtr_pi_std, x_valid_dtr_pi_std, y_valid_dtr_pi_std = data_divide(data_dtr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtr_pi_minmax = norm_minmax(data_dtr_pi, variables_dtr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtr_pi_minmax, y_train_dtr_pi_minmax, x_test_dtr_pi_minmax, y_test_dtr_pi_minmax, x_valid_dtr_pi_minmax, y_valid_dtr_pi_minmax = data_divide(data_dtr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rfr_pi = pd.DataFrame({'radiacao': data2['radiacao'],\n",
    "                            'hora': data2['hora'],\n",
    "                            'pressao_atm': data2['pressao_atm'],\n",
    "                            'temperatura': data2['temperatura'],\n",
    "                            'umidade': data2['umidade']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_rfr_pi = ['radiacao', 'hora', 'pressao_atm', 'temperatura', 'umidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rfr_pi_std = norm_std(data_rfr_pi, variables_rfr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rfr_pi_std, y_train_rfr_pi_std, x_test_rfr_pi_std, y_test_rfr_pi_std, x_valid_rfr_pi_std, y_valid_rfr_pi_std = data_divide(data_rfr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rfr_pi_minmax = norm_minmax(data_rfr_pi, variables_rfr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rfr_pi_minmax, y_train_rfr_pi_minmax, x_test_rfr_pi_minmax, y_test_rfr_pi_minmax, x_valid_rfr_pi_minmax, y_valid_rfr_pi_minmax = data_divide(data_rfr_pi_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_knn_pi = pd.DataFrame({'radiacao': data2['radiacao'],\n",
    "                            'hora': data2['hora'],\n",
    "                            'temperatura': data2['temperatura'],\n",
    "                            'umidade': data2['umidade']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_knn_pi = ['radiacao', 'hora', 'temperatura', 'umidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_knn_pi_std = norm_std(data_rfr_pi, variables_rfr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_knn_pi_std, y_train_knn_pi_std, x_test_knn_pi_std, y_test_knn_pi_std, x_valid_knn_pi_std, y_valid_knn_pi_std = data_divide(data_knn_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_knn_pi_minmax = norm_minmax(data_rfr_pi, variables_rfr_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_knn_pi_minmax, y_train_knn_pi_minmax, x_test_knn_pi_minmax, y_test_knn_pi_minmax, x_valid_knn_pi_minmax, y_valid_knn_pi_minmax = data_divide(data_knn_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5.4 - Machine Learning models training with Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Regressor (MLPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_pi_std = 0\n",
    "\n",
    "if control_mlpr_pi_std == 1:\n",
    "    \n",
    "    model_mlpr_pi_std = model_mlpr(x_train_mlpr_pi_std, y_train_mlpr_pi_std)\n",
    "\n",
    "    joblib.dump(model_mlpr_pi_std, 'ml_models/model_mlpr_pi_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_pi_std_test = 0\n",
    "\n",
    "if control_mlpr_pi_std_test == 1:\n",
    "\n",
    "    df_determined_mlpr_pi_std = model_test(model_mlpr_pi_std, x_test_mlpr_pi_std, y_test_mlpr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_pi_minmax = 0\n",
    "\n",
    "if control_mlpr_pi_minmax == 1:\n",
    "    \n",
    "    model_mlpr_pi_minmax = model_mlpr(x_train_mlpr_pi_minmax, y_train_mlpr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_mlpr_pi_minmax, 'ml_models/model_mlpr_pi_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_pi_minmax_test = 0\n",
    "\n",
    "if control_mlpr_piminmaxd_test == 1:\n",
    "\n",
    "    df_determined_mlpr_pi_minmax = model_test(model_mlpr_pi_minmax, x_test_mlpr_pi_minmax, y_test_mlpr_pi_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_pi_std = 0\n",
    "\n",
    "if control_dtr_pi_std == 1:\n",
    "    \n",
    "    model_dtr_pi_std = model_dtr(x_train_dtr_pi_std, y_train_dtr_pi_std)\n",
    "\n",
    "    joblib.dump(model_dtr_pi_std, 'ml_models/model_dtr_pi_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_pi_std_test = 0\n",
    "\n",
    "if control_dtr_pi_std_test == 1:\n",
    "\n",
    "    df_determined_dtr_pi_std = model_test(model_dtr_pi_std, x_test_dtr_pi_std, y_test_dtr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_pi_minmax = 0\n",
    "\n",
    "if control_dtr_pi_minmax == 1:\n",
    "    \n",
    "    model_dtr_pi_minmax = model_dtr(x_train_dtr_pi_minmax, y_train_dtr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_dtr_pi_minmax, 'ml_models/model_dtr_pi_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_pi_minmax_test = 0\n",
    "\n",
    "if control_dtr_pi_minmax_test == 1:\n",
    "\n",
    "    df_determined_dtr_pi_minmax = model_test(model_dtr_pi_minmax, x_test_dtr_pi_minmax, y_test_dtr_pi_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_pi_std = 0\n",
    "\n",
    "if control_rfr_pi_std == 1:\n",
    "    \n",
    "    model_rfr_pi_std = model_rfr(x_train_rfr_pi_std, y_train_rfr_pi_std)\n",
    "\n",
    "    joblib.dump(model_rfr_pi_std, 'ml_models/model_rfr_pi_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_pi_std_test = 0\n",
    "\n",
    "if control_rfr_pi_std_test == 1:\n",
    "\n",
    "    df_determined_rfr_pi_std = model_test(model_rfr_pi_std, x_test_rfr_pi_std, y_test_rfr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_pi_minmax = 0\n",
    "\n",
    "if control_rfr_pi_minmax == 1:\n",
    "    \n",
    "    model_rfr_pi_minmax = model_rfr(x_train_rfr_pi_minmax, y_train_rfr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_rfr_pi_minmax, 'ml_models/model_rfr_pi_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_pi_minmax_test = 0\n",
    "\n",
    "if control_rfr_pi_minmax_test == 1:\n",
    "\n",
    "    df_determined_rfr_pi_minmax = model_test(model_rfr_pi_minmax, x_test_rfr_pi_minmax, y_test_rfr_pi_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_pi_std = 0\n",
    "\n",
    "if control_knn_pi_std == 1:\n",
    "    \n",
    "    model_knn_pi_std = model_knn(x_train_knn_pi_std, y_train_knn_pi_std)\n",
    "\n",
    "    joblib.dump(model_knn_pi_std, 'ml_models/model_knn_pi_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_pi_std_test = 0\n",
    "\n",
    "if control_knn_pi_std_test == 1:\n",
    "\n",
    "    df_determined_knn_pi_std = model_test(model_knn_pi_std, x_test_knn_pi_std, y_test_knn_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_pi_minmax = 0\n",
    "\n",
    "if control_knn_pi_minmax == 1:\n",
    "    \n",
    "    model_knn_pi_minmax = model_knn(x_train_knn_pi_minmax, y_train_knn_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_knn_pi_minmax, 'ml_models/model_knn_pi_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_pi_minmax_test = 0\n",
    "\n",
    "if control_knn_pi_minmax_test == 1:\n",
    "\n",
    "    df_determined_knn_pi_minmax = model_test(model_knn_pi_minmax, x_test_knn_pi_minmax, y_test_knn_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5.5 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "# ====================================================================================================================== #\n",
    "# | ML with data STD normalization                             | | ML with data MINMAX normalization                   | #\n",
    "# ====================================================================================================================== #\n",
    "#                                                                                                                        #\n",
    "# MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)                          #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# DecisionTreeRegressor(max_depth=100, min_samples_leaf=2, random_state = 42)                                            #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo'                       #\n",
    "#                                                                                                                        #\n",
    "# RandomForestRegressor(n_estimators=100, max_depth=50, min_samples_leaf=2, random_state = 42)                           #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'umidade'                                                                        #\n",
    "#                                                                                                                        #\n",
    "# KNeighborsRegressor(n_neighbors=3, leaf_size=30, weights='distance', algorithm='auto', metric='euclidean')             #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# ====================================================================================================================== #\n",
    "# |      |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MAE  |                 | 0.1863 | 0.2292 | 0.1847 | 0.2141 | |                 | 0.0335 | 0.0412 | 0.0332 | 0.0385 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MSE  |                 | 0.1264 | 0.2042 | 0.1290 | 0.1702 | |                 | 0.0041 | 0.0066 | 0.0041 | 0.0055 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | RMSE |                 | 0.3556 | 0.4519 | 0.3592 | 0.4126 | |                 | 0.0640 | 0.0812 | 0.0645 | 0.0742 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | R2   |                 | 0.8734 | 0.7956 | 0.8709 | 0.8297 | |                 | 0.8728 | 0.7955 | 0.8709 | 0.8296 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttrn |                 | 12m9s  | 40.9s  | 30m12s | 9,8s   | |                 | 10m55s | 40.9s  | 31m22s | 9,4s   | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttst |                 | 6.5s   | 1.0s   | 4m46s  | 25,2s  | |                 | 4.1s   | 1.0s   | 4m46s  | 32,4s  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By the maintenance on values of errors and precision (R2)\n",
    "# and the significant reduce of variables quantities in some ML models\n",
    "# we'll keep this variables to optimize the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 6 - Optimization of parameters of ML models**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of optimization\n",
    "\n",
    "def grid_search_cv_model(model, x_train, x_test, y_train, y_test, parameters_grid, filename=None):\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, parameters_grid=parameters_grid, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    best_parameters = grid_search.best_params_\n",
    "\n",
    "    performance = grid_search.score(x_test, y_test)\n",
    "\n",
    "    print(\"Best parameters:\", best_parameters)\n",
    "    print(\"Performance:\", performance)\n",
    "\n",
    "    print('-'*60)\n",
    "    cvres = grid_search.cv_results_\n",
    "    for mean_score, parameters_grid in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), parameters_grid)\n",
    "\n",
    "    result_grid_search_cv = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    if filename is not None:\n",
    "        result_grid_search_cv.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6.1 - Multilayer Perceptron Regressor (MLPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_mlpr_1 = {\n",
    "    'hidden_layer_sizes': [(15, 8), (30, 15), (60, 30)],\n",
    "    'activation': ['relu'], \n",
    "    'solver': ['adam'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_mlpr_opt_1 = MLPRegressor()\n",
    "\n",
    "grid_search_cv_model(model_mlpr_opt_1, x_train_mlpr_pi_std, x_test_mlpr_pi_std, y_train_mlpr_pi_std, y_test_mlpr_pi_std, parameters_grid_mlpr_1, 'ml_models/result_grid_search_cv_mlpr_opt_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_mlpr_2 = {\n",
    "    'hidden_layer_sizes': [(45, 15), (60, 30), (75, 45)],\n",
    "    'activation': ['relu'], \n",
    "    'solver': ['adam'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_mlpr_opt_2 = MLPRegressor()\n",
    "\n",
    "grid_search_cv_model(model_mlpr_opt_2, x_train_mlpr_pi_std, x_test_mlpr_pi_std, y_train_mlpr_pi_std, y_test_mlpr_pi_std, parameters_grid_mlpr_2, 'ml_models/result_grid_search_cv_mlpr_opt_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times:\n",
    "# model_mlpr_opt_1 = 102m56.5s\n",
    "# model_mlpr_opt_2 = 171m12.7s\n",
    "\n",
    "# Parameters: (hidden_layer_sizes=(60, 30), activation='relu', solver='adam', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mlpr_opt(x_train, y_train):\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=(60, 30), activation='relu', solver='adam', random_state=42)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_opt_std = 0\n",
    "\n",
    "if control_mlpr_opt_std == 1:\n",
    "    \n",
    "    model_mlpr_opt_std = model_mlpr_opt(x_train_mlpr_pi_std, y_train_mlpr_pi_std)\n",
    "\n",
    "    joblib.dump(model_mlpr_opt_std, 'ml_models/model_mlpr_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_opt_std_test = 0\n",
    "\n",
    "if control_mlpr_opt_std_test == 1:\n",
    "\n",
    "    df_determined_mlpr_opt_std = model_test(model_mlpr_opt_std, x_test_mlpr_pi_std, y_test_mlpr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_opt_minmax = 0\n",
    "\n",
    "if control_mlpr_opt_minmax == 1:\n",
    "    \n",
    "    model_mlpr_opt_minmax = model_mlpr_opt(x_train_mlpr_pi_minmax, y_train_mlpr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_mlpr_opt_minmax, 'ml_models/model_mlpr_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mlpr_opt_minmax_test = 0\n",
    "\n",
    "if control_mlpr_opt_minmax_test == 1:\n",
    "\n",
    "    df_determined_mlpr_opt_minmax = model_test(model_mlpr_opt_minmax, x_test_mlpr_pi_minmax, y_test_mlpr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6.2 - Decision Tree Regressor (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_dtr_1 = {\n",
    "    'max_depth': [25, 50, 100],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_dtr_opt_1 = DecisionTreeRegressor()\n",
    "\n",
    "grid_search_cv_model(model_dtr_opt_1, x_train_dtr_pi_std, x_test_dtr_pi_std, y_train_dtr_pi_std, y_test_dtr_pi_std, parameters_grid_dtr_1, 'ml_models/result_grid_search_cv_dtr_opt_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_dtr_2 = {\n",
    "    'max_depth': [10, 17, 24],\n",
    "    'min_samples_leaf': [5, 10, 15],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_dtr_opt_2 = DecisionTreeRegressor()\n",
    "\n",
    "grid_search_cv_model(model_dtr_opt_2, x_train_dtr_pi_std, x_test_dtr_pi_std, y_train_dtr_pi_std, y_test_dtr_pi_std, parameters_grid_dtr_2, 'ml_models/result_grid_search_cv_dtr_opt_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_dtr_3 = {\n",
    "    'max_depth': [14, 17, 20],\n",
    "    'min_samples_leaf': [15, 18, 21],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_dtr_opt_3 = DecisionTreeRegressor()\n",
    "\n",
    "grid_search_cv_model(model_dtr_opt_3, x_train_dtr_pi_std, x_test_dtr_pi_std, y_train_dtr_pi_std, y_test_dtr_pi_std, parameters_grid_dtr_3, 'ml_models/result_grid_search_cv_dtr_opt_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times:\n",
    "# model_dtr_opt_1 = 54m36.3s\n",
    "# model_dtr_opt_2 = 38m11.8s\n",
    "# model_dtr_opt_3 = 32m24.3s\n",
    "\n",
    "# Parameters: (max_depth=17, min_samples_leaf=18, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtr_opt(x_train, y_train):\n",
    "\n",
    "    model = DecisionTreeRegressor(max_depth=17, min_samples_leaf=18, random_state = 42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_opt_std = 0\n",
    "\n",
    "if control_dtr_opt_std == 1:\n",
    "    \n",
    "    model_dtr_opt_std = model_dtr_opt(x_train_dtr_pi_std, y_train_dtr_pi_std)\n",
    "\n",
    "    joblib.dump(model_dtr_opt_std, 'ml_models/model_dtr_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_opt_std_test = 0\n",
    "\n",
    "if control_dtr_opt_std_test == 1:\n",
    "\n",
    "    df_determined_dtr_opt_std = model_test(model_dtr_opt_std, x_test_dtr_pi_std, y_test_dtr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_opt_minmax = 0\n",
    "\n",
    "if control_dtr_opt_minmax == 1:\n",
    "    \n",
    "    model_dtr_opt_minmax = model_dtr_opt(x_train_dtr_pi_minmax, y_train_dtr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_dtr_opt_minmax, 'ml_models/model_dtr_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dtr_opt_minmax_test = 0\n",
    "\n",
    "if control_dtr_opt_minmax_test == 1:\n",
    "\n",
    "    df_determined_dtr_opt_minmax = model_test(model_dtr_opt_minmax, x_test_dtr_pi_minmax, y_test_dtr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6.3 - Random Forest Regressor (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_rfr_1 = {\n",
    "    'n_estimators': [30, 50, 70],\n",
    "    'max_depth': [10, 25, 40],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model_rfr_opt_1 = RandomForestRegressor()\n",
    "\n",
    "grid_search_cv_model(model_rfr_opt_1, x_train_rfr_pi_std, x_test_rfr_pi_std, y_train_rfr_pi_std, y_test_rfr_pi_std, parameters_grid_rfr_1, 'ml_models/result_grid_search_cv_rfr_opt_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times:\n",
    "# model_rfr_opt_1 = 2750m29.4s\n",
    "\n",
    "# Parameters: (max_depth=25, min_samples_leaf=10, n_estimators=70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rfr_opt(x_train, y_train):\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=70, max_depth=25, min_samples_leaf=10, random_state = 42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_opt_std = 0\n",
    "\n",
    "if control_rfr_opt_std == 1:\n",
    "    \n",
    "    model_rfr_opt_std = model_rfr_opt(x_train_rfr_pi_std, y_train_rfr_pi_std)\n",
    "\n",
    "    joblib.dump(model_rfr_opt_std, 'ml_models/model_rfr_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_opt_std_test = 0\n",
    "\n",
    "if control_rfr_opt_std_test == 1:\n",
    "\n",
    "    df_determined_rfr_opt_std = model_test(model_rfr_opt_std, x_test_rfr_pi_std, y_test_rfr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_opt_minmax = 0\n",
    "\n",
    "if control_rfr_opt_minmax == 1:\n",
    "    \n",
    "    model_rfr_opt_minmax = model_rfr_opt(x_train_rfr_pi_minmax, y_train_rfr_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_rfr_opt_minmax, 'ml_models/model_rfr_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_rfr_opt_minmax_test = 0\n",
    "\n",
    "if control_rfr_opt_minmax_test == 1:\n",
    "\n",
    "    df_determined_rfr_opt_minmax = model_test(model_rfr_opt_minmax, x_test_rfr_pi_minmax, y_test_rfr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6.4 - K Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_knn_1 = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11],\n",
    "    'leaf_size': [30, 50, 70],\n",
    "    'weights': ['distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "model_knn_opt_1 = KNeighborsRegressor()\n",
    "\n",
    "grid_search_cv_model(model_knn_opt_1, x_train_knn_pi_std, x_test_knn_pi_std, y_train_knn_pi_std, y_test_knn_pi_std, parameters_grid_knn_1, 'ml_models/result_grid_search_cv_knn_opt_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid_knn_2 = {\n",
    "    'n_neighbors': [11, 15, 19, 23, 27],\n",
    "    'leaf_size': [10, 20, 30],\n",
    "    'weights': ['distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'metric': ['euclidean']\n",
    "}\n",
    "\n",
    "model_knn_opt_2 = KNeighborsRegressor()\n",
    "\n",
    "grid_search_cv_model(model_knn_opt_2, x_train_knn_pi_std, x_test_knn_pi_std, y_train_knn_pi_std, y_test_knn_pi_std, parameters_grid_knn_2, 'ml_models/result_grid_search_cv_knn_opt_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times:\n",
    "# model_knn_opt_1 = 41m6.7s\n",
    "# model_knn_opt_1 = 17m3,9s\n",
    "\n",
    "# Parameters: (n_neighbors=70, leaf_size=50, weights='distance', algorithm='auto', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_knn_opt(x_train, y_train):\n",
    "\n",
    "    model = KNeighborsRegressor(n_neighbors=70, leaf_size=50, weights='distance', algorithm='auto', metric='euclidean')\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_opt_std = 0\n",
    "\n",
    "if control_knn_opt_std == 1:\n",
    "    \n",
    "    model_knn_opt_std = model_knn_opt(x_train_knn_pi_std, y_train_knn_pi_std)\n",
    "\n",
    "    joblib.dump(model_knn_opt_std, 'ml_models/model_knn_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_opt_std_test = 0\n",
    "\n",
    "if control_knn_opt_std_test == 1:\n",
    "\n",
    "    df_determined_knn_opt_std = model_test(model_knn_opt_std, x_test_knn_pi_std, y_test_knn_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_opt_minmax = 0\n",
    "\n",
    "if control_knn_opt_minmax == 1:\n",
    "    \n",
    "    model_knn_opt_minmax = model_knn_opt(x_train_knn_pi_minmax, y_train_knn_pi_minmax)\n",
    "\n",
    "    joblib.dump(model_knn_opt_minmax, 'ml_models/model_knn_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_knn_opt_minmax_test = 0\n",
    "\n",
    "if control_knn_opt_minmax_test == 1:\n",
    "\n",
    "    df_determined_knn_opt_minmax = model_test(model_knn_opt_minmax, x_test_knn_pi_minmax, y_test_knn_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6.5 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "# ====================================================================================================================== #\n",
    "# | ML with data STD normalization                             | | ML with data MINMAX normalization                   | #\n",
    "# ====================================================================================================================== #\n",
    "#                                                                                                                        #\n",
    "# MLPRegressor(hidden_layer_sizes=(60, 30), activation='relu', solver='adam', random_state=42)                           #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# DecisionTreeRegressor(max_depth=17, min_samples_leaf=18, random_state = 42)                                            #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo'                       #\n",
    "#                                                                                                                        #\n",
    "# RandomForestRegressor(n_estimators=70, max_depth=25, min_samples_leaf=10, random_state = 42)                           #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'umidade'                                                                        #\n",
    "#                                                                                                                        #\n",
    "# KNeighborsRegressor(n_neighbors=27, leaf_size=10, weights='distance', algorithm='auto', metric='euclidean')            #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# ====================================================================================================================== #\n",
    "# |      |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | |                 | *MLPR* | *DTR*  | *RFR*  | *KNN*  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MAE  |                 | 0.1869 | 0.1747 | 0.1766 | 0.1910 | |                 | 0.0333 | 0.0314 | 0.0317 | 0.0343 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | MSE  |                 | 0.1268 | 0.1171 | 0.1187 | 0.1360 | |                 | 0.0041 | 0.0037 | 0.0038 | 0.0043 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | RMSE |                 | 0.3562 | 0.3422 | 0.3446 | 0.3687 | |                 | 0.0642 | 0.0615 | 0.0619 | 0.0662 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | R2   |                 | 0.8730 | 0.8828 | 0.8812 | 0.8639 | |                 | 0.8721 | 0.8828 | 0.8812 | 0.8639 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttrn |                 | 7m21s  | 30.9s  | 16m51s | 12,5s  | |                 | 8m32s  | 32.0s  | 18m59s | 9,3s   | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | ttst |                 | 3.2s   | 0.3s   | 37.2s  | 1m20s  | |                 | 3.6s   | 0.4s   | 39,3s  | 1m36s  | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 7 - Cross validation of ML models optmize**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.1 - Loading ML optmize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD\n",
    "\n",
    "model_mlpr_opt_std = joblib.load('ml_models/model_mlpr_opt_std.pkl')\n",
    "model_dtr_opt_std = joblib.load('ml_models/model_dtr_opt_std.pkl')\n",
    "model_rfr_opt_std = joblib.load('ml_models/model_rfr_opt_std.pkl')\n",
    "model_knn_opt_std = joblib.load('ml_models/model_knn_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX\n",
    "\n",
    "model_mlpr_opt_minmax = joblib.load('ml_models/model_mlpr_opt_minmax.pkl')\n",
    "model_dtr_opt_minmax = joblib.load('ml_models/model_dtr_opt_minmax.pkl')\n",
    "model_rfr_opt_minmax = joblib.load('ml_models/model_rfr_opt_minmax.pkl')\n",
    "model_knn_opt_minmax = joblib.load('ml_models/model_knn_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.2 - Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cross_val(model, x_valid, y_valid):\n",
    "\n",
    "    scores = cross_val_score(model, x_valid, y_valid, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    y_pred = cross_val_predict(model, x_valid, y_valid, cv=10)\n",
    "\n",
    "    POINTS = np.sqrt(-scores)\n",
    "    MEAN = POINTS.mean()\n",
    "    SD = POINTS.std()\n",
    "    R2 = metrics.r2_score(y_valid, y_pred)\n",
    "\n",
    "    print('-'*60)\n",
    "    print('Score:', POINTS)\n",
    "    print('Mean:', MEAN)\n",
    "    print('Standard Deviation:', SD)\n",
    "    print('R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.3 - Multilayer Perceptron Regressor (MLPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_mlpr_std = 0\n",
    "\n",
    "if control_validation_mlpr_std == 1:\n",
    "    \n",
    "    score_cross_val(model_mlpr_opt_std, x_valid_mlpr_pi_std, y_valid_mlpr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX MLPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_mlpr_minmax = 0\n",
    "\n",
    "if control_validation_mlpr_minmax == 1:\n",
    "    \n",
    "    score_cross_val(model_mlpr_opt_minmax, x_valid_mlpr_pi_minmax, y_valid_mlpr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.4 - Decision Tree Regressor (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_dtr_std = 0\n",
    "\n",
    "if control_validation_dtr_std == 1:\n",
    "    \n",
    "    score_cross_val(model_dtr_opt_std, x_valid_dtr_pi_std, y_valid_dtr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_dtr_minmax = 0\n",
    "\n",
    "if control_validation_dtr_minmax == 1:\n",
    "    \n",
    "    score_cross_val(model_dtr_opt_minmax, x_valid_dtr_pi_minmax, y_valid_dtr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.5 - Random Forest Regressor (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_rfr_std = 0\n",
    "\n",
    "if control_validation_rfr_std == 1:\n",
    "    \n",
    "    score_cross_val(model_rfr_opt_std, x_valid_rfr_pi_std, y_valid_rfr_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_rfr_minmax = 0\n",
    "\n",
    "if control_validation_rfr_minmax == 1:\n",
    "    \n",
    "    score_cross_val(model_rfr_opt_minmax, x_valid_rfr_pi_minmax, y_valid_rfr_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.6 - K Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_knn_std = 0\n",
    "\n",
    "if control_validation_knn_std == 1:\n",
    "    \n",
    "    score_cross_val(model_knn_opt_std, x_valid_knn_pi_std, y_valid_knn_pi_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_validation_knn_minmax = 0\n",
    "\n",
    "if control_validation_knn_minmax == 1:\n",
    "    \n",
    "    score_cross_val(model_knn_opt_minmax, x_valid_knn_pi_minmax, y_valid_knn_pi_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7.7 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "# ====================================================================================================================== #\n",
    "# | ML with data STD normalization                             | | ML with data MINMAX normalization                   | #\n",
    "# ====================================================================================================================== #\n",
    "#                                                                                                                        #\n",
    "# MLPRegressor(hidden_layer_sizes=(60, 30), activation='relu', solver='adam', random_state=42)                           #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# DecisionTreeRegressor(max_depth=17, min_samples_leaf=18, random_state = 42)                                            #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo'                       #\n",
    "#                                                                                                                        #\n",
    "# RandomForestRegressor(n_estimators=70, max_depth=25, min_samples_leaf=10, random_state = 42)                           #\n",
    "# 'hora', 'pressao_atm', 'temperatura', 'umidade'                                                                        #\n",
    "#                                                                                                                        #\n",
    "# KNeighborsRegressor(n_neighbors=27, leaf_size=10, weights='distance', algorithm='auto', metric='euclidean')            #\n",
    "# 'hora', 'temperatura', 'umidade'                                                                                       #\n",
    "#                                                                                                                        #\n",
    "# ====================================================================================================================== #\n",
    "# |      |             | *MLPR*  | *DTR*   | *RFR*   | *KNN*   | |             | *MLPR*  | *DTR*   | *RFR*   | *KNN*   | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | mean |             | 0.35864 | 0.35789 | 0.34934 | 0.42009 | |             | 0.06504 | 0.06435 | 0.06281 | 0.07548 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | stdv |             | 0.00178 | 0.00204 | 0.00208 | 0.00201 | |             | 0.00044 | 0.00037 | 0.00037 | 0.00036 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | R2   |             | 0.87120 | 0.87173 | 0.87779 | 0.82328 | |             | 0.86897 | 0.87172 | 0.87779 | 0.82348 | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "# | tvld |             | 1019,0  | 71,6    | 2119,0  | 72,6    | |             | 1218,9  | 60,6    | 2260,4  | 74,3    | #\n",
    "# ---------------------------------------------------------------------------------------------------------------------- #\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the scores, errors and precision (R2) of ML models optimizeds\n",
    "# the MLPR and DTR were choosed to next steps of evaluation with specifics tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Step 8 - Application of models**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD\n",
    "\n",
    "model_mlpr_opt_std = joblib.load('ml_models/model_mlpr_opt_std.pkl')\n",
    "model_dtr_opt_std = joblib.load('ml_models/model_dtr_opt_std.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlpr_opt_std, model_dtr_opt_std, model_mlpr_opt_minmax, model_dtr_opt_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX\n",
    "\n",
    "model_mlpr_opt_minmax = joblib.load('ml_models/model_mlpr_opt_minmax.pkl')\n",
    "model_dtr_opt_minmax = joblib.load('ml_models/model_dtr_opt_minmax.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Analysis of most important variables\n",
    "\n",
    "- 'hora', \n",
    "- 'pressao_atm', \n",
    "- 'temperatura', \n",
    "- 'temp_orvalho', \n",
    "- 'umidade', \n",
    "- 'direcao_vento', \n",
    "- 'vento_maximo'.\n",
    "\n",
    "By each meteorological station, on a specific date by DD/MM/YYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select the station\n",
    "\n",
    "def select_station(string_station, data_stations):\n",
    "\n",
    "    index_select_station = np.array(data_stations.index)\n",
    "\n",
    "    for index in index_select_station:\n",
    "\n",
    "        station = data_stations.loc[index, 'nome']\n",
    "\n",
    "        if station == string_station:\n",
    "            print(index, 'station', station)\n",
    "            print(data_stations.loc[index])\n",
    "            file = data_stations.loc[index, 'csv']\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    station_data = pd.read_csv(file, skiprows=10, delimiter=\";\", decimal=\",\")\n",
    "    station_data.drop(station_data.columns[[4,5,6,8,11,12,13,14,15,16,17,22]],axis=1, inplace = True)\n",
    "    station_data.dropna(inplace=True)\n",
    "\n",
    "    result = pd.concat([result, station_data])\n",
    "\n",
    "    result.rename(columns = {'Data Medicao': 'data'}, inplace = True)\n",
    "    result['data'] = pd.to_datetime(result['data'])\n",
    "    result.rename(columns = {'Hora Medicao': 'hora'}, inplace = True)\n",
    "    result.rename(columns = {'PRECIPITACAO TOTAL, HORARIO(mm)': 'precipitacao'}, inplace = True)\n",
    "    result.rename(columns = {'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA(mB)': 'pressao_atm'}, inplace = True)\n",
    "    result.rename(columns = {'RADIACAO GLOBAL(Kj/m²)': 'radiacao'}, inplace = True)\n",
    "    result.rename(columns = {'TEMPERATURA DO AR - BULBO SECO, HORARIA(°C)': 'temperatura'}, inplace = True)\n",
    "    result.rename(columns = {'TEMPERATURA DO PONTO DE ORVALHO(°C)': 'temp_orvalho'}, inplace = True)\n",
    "    result.rename(columns = {'UMIDADE RELATIVA DO AR, HORARIA(%)': 'umidade'}, inplace = True)\n",
    "    result.rename(columns = {'VENTO, DIRECAO HORARIA (gr)(° (gr))': 'direcao_vento'}, inplace = True)\n",
    "    result.rename(columns = {'VENTO, RAJADA MAXIMA(m/s)': 'vento_maximo'}, inplace = True)\n",
    "    result.rename(columns = {'VENTO, VELOCIDADE HORARIA(m/s)': 'velocidade'}, inplace = True)\n",
    "\n",
    "    result = adjust_hour(result)\n",
    "    result = remove_out(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return data by date\n",
    "# year = 0; month = 1; day = 2\n",
    "\n",
    "def data_by_date(df, type, date):\n",
    " \n",
    "    if type == 0:\n",
    "        df_date = df[df['data'].dt.year == date]\n",
    "        \n",
    "    if type == 1:\n",
    "        df_date = df[df['data'].dt.month == date]\n",
    "            \n",
    "    if type == 2:\n",
    "        df_date = df[df['data'].dt.day == date]\n",
    "        \n",
    "    return df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return data  by day/month/year\n",
    "\n",
    "def data_by_ddmmyyyy(df, day, month, year):\n",
    "    \n",
    "    data_yyyy = data_by_date(df, 0, year)\n",
    "\n",
    "    data_mmyyyy = data_by_date(data_yyyy, 1, month)\n",
    "\n",
    "    data_ddmmyyyy = data_by_date(data_mmyyyy, 2, day)\n",
    "\n",
    "    return data_ddmmyyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print station data and variables values\n",
    "\n",
    "def variables_analysis_ddmmyyyy(string_station, data_stations, day, month, year, local_save):\n",
    "\n",
    "    station = select_station(string_station, data_stations)\n",
    "\n",
    "    data_station = data_by_ddmmyyyy(station, day, month, year)\n",
    "\n",
    "    variables = ['temperatura', 'umidade', 'pressao_atm', 'direcao_vento', 'vento_maximo', 'temp_orvalho']\n",
    "    colors = ['#FFC300', '#00D3FF', '#515151', '#C900FF', '#D954FD', '#EB8A00']\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for ax, variable in zip(axes.flat, variables):\n",
    "\n",
    "        y_axis = data_station[variable]\n",
    "        y_color = colors[i]\n",
    "\n",
    "        ax.plot(data_station['hora'], y_axis, color=y_color)\n",
    "\n",
    "        ax.grid(alpha=0.5)\n",
    "        ax.set_xlabel('hora')\n",
    "        ax.set_xticks(data_station['hora'])\n",
    "        ax.set_ylabel(variable)\n",
    "        ax.set_title(variable)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    fig.suptitle(f'Variables x hour {string_station} {day}/{month}/{year}')\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "    save_path = f'{local_save}/{string_station}_variables_{day}_{month}_{year}'\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_analysis_ddmmyyyy('NOVA FATIMA', selected_stations, 1, 1, 2010, 'figures_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.2 Analysis of precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to select data of station by day, month and year separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_year(df, year):\n",
    "    \n",
    "    data_year = data_by_date(df, 0, year)\n",
    "\n",
    "    return data_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_month_year(df, month, year):\n",
    "    \n",
    "    data_year = data_by_date(df, 0, year)\n",
    "\n",
    "    data_month_year = data_by_date(data_year, 1, month)\n",
    "\n",
    "    return data_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_day_month_year(df, day, month, year):\n",
    "    \n",
    "    data_year = data_by_date(df, 0, year)\n",
    "\n",
    "    data_month_year = data_by_date(data_year, 1, month)\n",
    "\n",
    "    data_day_month_year = data_by_date(data_month_year, 2, day)\n",
    "\n",
    "    return data_day_month_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function linear plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_plot(df, x, y, title, save_path=None):\n",
    "\n",
    "    plot = df.plot(x=x, y=y, figsize=(15, 5), color = '#0033FE')\n",
    "\n",
    "    plot.grid(alpha=0.25)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_plot_hour(df, y, title, save_path=None):\n",
    "\n",
    "    plot = df.plot(x='hora', y=y, figsize=(15, 5), color = '#0033FE')\n",
    "\n",
    "    plot.grid(alpha=0.25)\n",
    "    plt.xlabel('hora')\n",
    "    plt.xticks(df['hora'])\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check precipitation values on a station in a day, month and year \n",
    "\n",
    "def check_precipitation(string_station, data_stations, day, month, year, local_save):\n",
    "\n",
    "    station = select_station(string_station, data_stations)\n",
    "    \n",
    "    data_station_yyyy = data_year(station, year)\n",
    "    data_station_mmyyyy = data_month_year(station, month, year)\n",
    "    data_station_ddmmyyyy = data_day_month_year(station, day, month, year)\n",
    "\n",
    "    linear_plot(data_station_yyyy, 'data', 'precipitacao', f'Precipitation {string_station} {year}', None)\n",
    "    linear_plot(data_station_mmyyyy, 'data', 'precipitacao', f'Precipitation {string_station} {month}/{year}', None)\n",
    "    linear_plot_hour(data_station_ddmmyyyy, 'precipitacao', f'Precipitation {string_station} {day}/{month}/{year}', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_precipitation('UBERABA', selected_stations, 1, 4, 2020, 'figures_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3 Determination of radiation solar value in a specify date\n",
    "\n",
    "In this plot, is showing all info about models, values of test and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare and normalize data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_station_to_ml(name_model, df):\n",
    "\n",
    "    variables_mlpr = ['radiacao', 'hora', 'temperatura', 'umidade']\n",
    "\n",
    "    if name_model == 'MLPR':\n",
    "\n",
    "        df_mlpr = pd.DataFrame({'radiacao': df['radiacao'],\n",
    "                                'hora': df['hora'],\n",
    "                                'temperatura': df['temperatura'],\n",
    "                                'umidade': df['umidade']})\n",
    "\n",
    "        df_std = norm_std(df_mlpr, variables_mlpr)\n",
    "        df_minmax = norm_minmax(df_mlpr, variables_mlpr)\n",
    "\n",
    "    variables_dtr = ['radiacao', 'hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']\n",
    "\n",
    "    if name_model == 'DTR':\n",
    "\n",
    "        df_dtr = pd.DataFrame({'radiacao': df['radiacao'],\n",
    "                                'hora': df['hora'],\n",
    "                                'pressao_atm': df['pressao_atm'],\n",
    "                                'temperatura': df['temperatura'],\n",
    "                                'temp_orvalho': df['temp_orvalho'],\n",
    "                                'umidade': df['umidade'],\n",
    "                                'direcao_vento': df['direcao_vento'],\n",
    "                                'vento_maximo': df['vento_maximo']})\n",
    "\n",
    "        df_std = norm_std(df_dtr, variables_dtr)\n",
    "        df_minmax = norm_minmax(df_dtr, variables_dtr)\n",
    "\n",
    "    return df_std, df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to invert the normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_norm_std(df, df_determined):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_target = df.radiacao.values.reshape(-1,1) \n",
    "    scaler.fit(df_target)\n",
    "\n",
    "    data_measured_norm = df_determined.measured_rad.values.reshape(-1,1)\n",
    "    data_determined_norm = df_determined.determined_rad.values.reshape(-1,1)\n",
    "\n",
    "    data_measured = scaler.inverse_transform(data_measured_norm)\n",
    "    data_determined = scaler.inverse_transform(data_determined_norm)\n",
    "\n",
    "    combined_array = np.column_stack((data_measured, data_determined))\n",
    "\n",
    "    df_determined_inv = pd.DataFrame(combined_array, columns=['measured_rad', 'determined_rad'], index = df.index)\n",
    "\n",
    "    print('-'*60)\n",
    "    print(df_determined_inv)\n",
    "    print('-'*60)\n",
    "\n",
    "    data_station_determined = df.copy()\n",
    "    data_station_determined = pd.merge(data_station_determined, df_determined_inv['determined_rad'], left_index=True, right_index=True)\n",
    "\n",
    "    return df_determined_inv, data_station_determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_norm_minmax(df, df_determined):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    variables_minmax = ['measured_rad', 'determined_rad']\n",
    "\n",
    "    df_determined_inv = df_determined.copy()\n",
    "\n",
    "    df_target = df.radiacao.values.reshape(-1,1) \n",
    "    scaler.fit_transform(df_target)\n",
    "\n",
    "    df_determined_inv[variables_minmax] = scaler.inverse_transform(df_determined_inv[variables_minmax])\n",
    "    \n",
    "    print('-'*60)\n",
    "    print(df_determined_inv)\n",
    "    print('-'*60)\n",
    "\n",
    "    data_station_determined = df.copy()\n",
    "    data_station_determined = pd.merge(data_station_determined, df_determined_inv['determined_rad'], left_index=True, right_index=True)\n",
    "\n",
    "    return df_determined_inv, data_station_determined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determined the radiacao value and return with the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determined_mlpr(model, df):\n",
    "\n",
    "    index_data = np.array(df.index)\n",
    "\n",
    "    X_variables = df[['hora', 'temperatura', 'umidade']].values\n",
    "    y_target = df.radiacao.values.reshape(-1,1)\n",
    "\n",
    "    y_determined = model.predict(X_variables)\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_target, y_determined)\n",
    "    MSE = metrics.mean_squared_error(y_target, y_determined)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_target, y_determined))\n",
    "    R2 = metrics.r2_score(y_target, y_determined)\n",
    "\n",
    "    print('-'*60)\n",
    "    print('Mean Absolute Error:', MAE)\n",
    "    print('Mean Squared Error:', MSE)\n",
    "    print('Root Mean Squared Error:', RMSE)\n",
    "    print('R2 Score:', R2)\n",
    "\n",
    "    y_target = np.array(y_target)\n",
    "    y_determined = np.array(y_determined)\n",
    "\n",
    "    df_determined = pd.DataFrame({'measured_rad': y_target.flatten(), 'determined_rad': y_determined.flatten()}, index = index_data)\n",
    "\n",
    "    print('-'*60)\n",
    "    print(df_determined)\n",
    "    print('-'*60)\n",
    "\n",
    "    return df_determined, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determined_dtr(model, df):\n",
    "\n",
    "    index_data = np.array(df.index)\n",
    "\n",
    "    X_variables = df[['hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']].values\n",
    "    y_target = df.radiacao.values.reshape(-1,1)\n",
    "\n",
    "    y_determined = model.predict(X_variables)\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_target, y_determined)\n",
    "    MSE = metrics.mean_squared_error(y_target, y_determined)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_target, y_determined))\n",
    "    R2 = metrics.r2_score(y_target, y_determined)\n",
    "\n",
    "    print('-'*60)\n",
    "    print('Mean Absolute Error:', MAE)\n",
    "    print('Mean Squared Error:', MSE)\n",
    "    print('Root Mean Squared Error:', RMSE)\n",
    "    print('R2 Score:', R2)\n",
    "\n",
    "    y_target = np.array(y_target)\n",
    "    y_determined = np.array(y_determined)\n",
    "\n",
    "    df_determined = pd.DataFrame({'measured_rad': y_target.flatten(), 'determined_rad': y_determined.flatten()}, index = index_data)\n",
    "\n",
    "    print('-'*60)\n",
    "    print(df_determined)\n",
    "    print('-'*60)\n",
    "\n",
    "    return df_determined, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the line of 'radiacao' and 'radiacao_determinada' togheter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_together(df, x, y, measured, determined, R2, title, save_path=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    \n",
    "    ax.plot(df[x], df[measured], color='#000000', label=measured)\n",
    "\n",
    "    ax.plot(df[x], df[determined], color='red', label=f\"{determined} (R2={R2:.4f})\")\n",
    "\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_xticks(df[x])\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function application model\n",
    "# returning the values measured and determined\n",
    "# and the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(string_station, data_stations, day, month, year, model_name, norm_type, model, local_save):\n",
    "\n",
    "    data_station = select_station(string_station, data_stations)\n",
    "\n",
    "    data_station_ddmmyyyy = data_day_month_year(data_station, day, month, year)\n",
    "\n",
    "    data_std, data_minmax = data_station_to_ml(model_name, data_station_ddmmyyyy)\n",
    "\n",
    "    if model_name == 'MLPR':\n",
    "\n",
    "        if norm_type == 'STD':\n",
    "            df_determined_norm, R2 = determined_mlpr(model, data_std)\n",
    "            df_determined, data_station_determined_ddmmyyyy = inv_norm_std(data_station_ddmmyyyy, df_determined_norm)\n",
    "\n",
    "        if norm_type == 'MINMAX':\n",
    "            df_determined_norm, R2 = determined_mlpr(model, data_minmax)\n",
    "            df_determined, data_station_determined_ddmmyyyy = inv_norm_minmax(data_station_ddmmyyyy, df_determined_norm)\n",
    "\n",
    "    if model_name == 'DTR':\n",
    "        \n",
    "        if norm_type == 'STD':\n",
    "            df_determined_norm, R2 = determined_dtr(model, data_std)\n",
    "            df_determined, data_station_determined_ddmmyyyy = inv_norm_std(data_station_ddmmyyyy, df_determined_norm)\n",
    "\n",
    "        if norm_type == 'MINMAX':\n",
    "            df_determined_norm, R2 = determined_dtr(model, data_minmax)\n",
    "            df_determined, data_station_determined_ddmmyyyy = inv_norm_minmax(data_station_ddmmyyyy, df_determined_norm)\n",
    "\n",
    "    title = f'{string_station} {day}/{month}/{year} - {model_name} {norm_type}'\n",
    "    save_path = f'{local_save}/{string_station}_determined_{day}_{month}_{year}_{model_name}_{norm_type}'\n",
    "    \n",
    "    plot_line_together(data_station_determined_ddmmyyyy, 'hora', 'radiacao', 'radiacao', 'determined_rad', R2, title, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determined 'radiacao' value by the 4 models\n",
    "# MLPR STD & MINMAX\n",
    "# DTR STD & MINMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_models_determined(string_station, data_stations, day, month, year, local_save):\n",
    "\n",
    "    model_name = ['MLPR','DTR']\n",
    "    norm_type = ['STD','MINMAX']\n",
    "    models = [model_mlpr_opt_std, model_mlpr_opt_minmax, model_dtr_opt_std, model_dtr_opt_minmax]\n",
    "\n",
    "    print('-'*90)\n",
    "    print(f'{model_name[0]} {norm_type[0]}')\n",
    "    print('-'*90)\n",
    "    app(string_station, data_stations, day, month, year, model_name[0], norm_type[0], models[0], local_save)\n",
    "\n",
    "    print('-'*90)\n",
    "    print(f'{model_name[0]} {norm_type[1]}')\n",
    "    print('-'*90)\n",
    "    app(string_station, data_stations, day, month, year, model_name[0], norm_type[1], models[1], local_save)\n",
    "\n",
    "    print('-'*90)\n",
    "    print(f'{model_name[1]} {norm_type[0]}')\n",
    "    print('-'*90)\n",
    "    app(string_station, data_stations, day, month, year, model_name[1], norm_type[0], models[2], local_save)\n",
    "    \n",
    "    print('-'*90)\n",
    "    print(f'{model_name[1]} {norm_type[1]}')\n",
    "    print('-'*90)\n",
    "    app(string_station, data_stations, day, month, year, model_name[1], norm_type[1], models[3], local_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_models_determined('NOVA FATIMA', selected_stations, 1, 1, 2010, 'figures_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.4 Determination of radiation solar value in a weef\n",
    "\n",
    "In this plot, is showing all estipulation about the four models, values of test and plots, in a week starting on the date informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function clear to determined the radiacao value and return with the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determined_mlpr_clear(model, df):\n",
    "\n",
    "    index_data = np.array(df.index)\n",
    "\n",
    "    X_variables = df[['hora', 'temperatura', 'umidade']].values\n",
    "    y_target = df.radiacao.values.reshape(-1,1)\n",
    "\n",
    "    y_determined = model.predict(X_variables)\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_target, y_determined)\n",
    "    MSE = metrics.mean_squared_error(y_target, y_determined)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_target, y_determined))\n",
    "    R2 = metrics.r2_score(y_target, y_determined)\n",
    "\n",
    "    y_target = np.array(y_target)\n",
    "    y_determined = np.array(y_determined)\n",
    "\n",
    "    df_determined = pd.DataFrame({'measured_rad': y_target.flatten(), 'determined_rad': y_determined.flatten()}, index = index_data)\n",
    "\n",
    "    return df_determined, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determined_dtr_clear(model, df):\n",
    "\n",
    "    index_data = np.array(df.index)\n",
    "\n",
    "    X_variables = df[['hora', 'pressao_atm', 'temperatura', 'temp_orvalho', 'umidade', 'direcao_vento', 'vento_maximo']].values\n",
    "    y_target = df.radiacao.values.reshape(-1,1)\n",
    "\n",
    "    y_determined = model.predict(X_variables)\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_target, y_determined)\n",
    "    MSE = metrics.mean_squared_error(y_target, y_determined)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_target, y_determined))\n",
    "    R2 = metrics.r2_score(y_target, y_determined)\n",
    "\n",
    "    y_target = np.array(y_target)\n",
    "    y_determined = np.array(y_determined)\n",
    "\n",
    "    df_determined = pd.DataFrame({'measured_rad': y_target.flatten(), 'determined_rad': y_determined.flatten()}, index = index_data)\n",
    "\n",
    "    return df_determined, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions clear to invert the normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_norm_std_clear(df, df_determined):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_target = df.radiacao.values.reshape(-1,1) \n",
    "    scaler.fit(df_target)\n",
    "\n",
    "    data_measured_norm = df_determined.measured_rad.values.reshape(-1,1)\n",
    "    data_determined_norm = df_determined.determined_rad.values.reshape(-1,1)\n",
    "\n",
    "    data_measured = scaler.inverse_transform(data_measured_norm)\n",
    "    data_determined = scaler.inverse_transform(data_determined_norm)\n",
    "\n",
    "    combined_array = np.column_stack((data_measured, data_determined))\n",
    "\n",
    "    df_determined_inv = pd.DataFrame(combined_array, columns=['measured_rad', 'determined_rad'], index = df.index)\n",
    "\n",
    "    data_station_determined = df.copy()\n",
    "    data_station_determined = pd.merge(data_station_determined, df_determined_inv['determined_rad'], left_index=True, right_index=True)\n",
    "\n",
    "    return df_determined_inv, data_station_determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_norm_minmax_clear(df, df_determined):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    variables_minmax = ['measured_rad', 'determined_rad']\n",
    "\n",
    "    df_determined_inv = df_determined.copy()\n",
    "\n",
    "    df_target = df.radiacao.values.reshape(-1,1) \n",
    "    scaler.fit_transform(df_target)\n",
    "\n",
    "    df_determined_inv[variables_minmax] = scaler.inverse_transform(df_determined_inv[variables_minmax])\n",
    "\n",
    "    data_station_determined = df.copy()\n",
    "    data_station_determined = pd.merge(data_station_determined, df_determined_inv['determined_rad'], left_index=True, right_index=True)\n",
    "\n",
    "    return df_determined_inv, data_station_determined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the calculation off models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determined_models(df):\n",
    "\n",
    "    list_models = ['MLPR','DTR']\n",
    "    models = [model_mlpr_opt_std, model_dtr_opt_std, model_mlpr_opt_minmax, model_dtr_opt_minmax]\n",
    "\n",
    "    df_std, df_minmax = data_station_to_ml(list_models[0], df)\n",
    "\n",
    "    # PRED - MLPR - STD\n",
    "    df_det_mlpr_std, R2_mlpr_std = determined_mlpr_clear(models[0], df_std)\n",
    "    df_det_inv_mlpr_std, data_det_mlpr_std = inv_norm_std_clear(df, df_det_mlpr_std)\n",
    "\n",
    "    # PRED - MLPR - MINMAX\n",
    "    df_det_mlpr_minmax, R2_mlpr_minmax = determined_mlpr_clear(models[1], df_minmax)\n",
    "    df_det_inv_mlpr_minmax, data_det_mlpr_minmax = inv_norm_minmax_clear(df, df_det_mlpr_minmax)\n",
    "\n",
    "    df_std, df_minmax = data_station_to_ml(list_models[1], df)\n",
    "\n",
    "    # PRED - DTR - STD\n",
    "    df_det_dtr_std, R2_dtr_std = determined_dtr_clear(models[2], df_std)\n",
    "    df_det_inv_dtr_std, data_det_dtr_std = inv_norm_std_clear(df, df_det_dtr_std)\n",
    "\n",
    "    # PRED - DTR - MINMAX\n",
    "    df_det_dtr_minmax, R2_dtr_minmax = determined_dtr_clear(models[3], df_minmax)\n",
    "    df_det_inv_dtr_minmax, data_det_dtr_minmax = inv_norm_minmax_clear(df, df_det_dtr_minmax)\n",
    "\n",
    "    return data_det_mlpr_std, R2_mlpr_std, data_det_mlpr_minmax, R2_mlpr_minmax, data_det_dtr_std, R2_dtr_std, data_det_dtr_minmax, R2_dtr_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the weekly determination of the irradiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_determined_radation_week(string_station, data_stations, day, month, year, local_save):\n",
    "\n",
    "    # Select data in the station select\n",
    "    data_station = select_station(string_station, data_stations)\n",
    "    \n",
    "    # Merge data determined per day\n",
    "    dfs = []\n",
    "    for i in range(7):\n",
    "        current_day = day + i\n",
    "\n",
    "        df_current_day = pd.DataFrame({'hora': range(24)})\n",
    "\n",
    "        data_station_day = data_day_month_year(data_station, current_day, month, year)\n",
    "            \n",
    "        det_mlpr_std, R2_mlpr_std, det_mlpr_minmax, R2_mlpr_minmax, det_dtr_std, R2_dtr_std, det_dtr_minmax, R2_dtr_minmax = determined_models(data_station_day)\n",
    "\n",
    "        df_current_day = df_current_day.merge(data_station_day[['hora', 'radiacao']], on='hora', how='left')\n",
    "        df_current_day = df_current_day.merge(det_mlpr_std[['hora', 'determined_rad']], on='hora', how='left').rename(columns={'determined_rad': 'determined_rad_mlpr_std'})\n",
    "        df_current_day = df_current_day.merge(det_mlpr_minmax[['hora', 'determined_rad']], on='hora', how='left').rename(columns={'determined_rad': 'determined_rad_mlpr_minmax'})\n",
    "        df_current_day = df_current_day.merge(det_dtr_std[['hora', 'determined_rad']], on='hora', how='left').rename(columns={'determined_rad': 'determined_rad_dtr_std'})\n",
    "        df_current_day = df_current_day.merge(det_dtr_minmax[['hora', 'determined_rad']], on='hora', how='left').rename(columns={'determined_rad': 'determined_rad_dtr_minmax'})\n",
    "\n",
    "        dfs.append(df_current_day)\n",
    "\n",
    "    # Merge data determined per week\n",
    "    df_week = pd.concat(dfs, ignore_index=True)\n",
    "    df_week['hora'] = df_week.index\n",
    "    df_week = df_week.dropna()\n",
    "    \n",
    "    # Metrics\n",
    "    R2_mlpr_std = metrics.r2_score(df_week['radiacao'], df_week['determined_rad_mlpr_std'])\n",
    "    R2_mlpr_minmax = metrics.r2_score(df_week['radiacao'], df_week['determined_rad_mlpr_minmax'])\n",
    "    R2_dtr_std = metrics.r2_score(df_week['radiacao'], df_week['determined_rad_dtr_std'])\n",
    "    R2_dtr_minmax = metrics.r2_score(df_week['radiacao'], df_week['determined_rad_dtr_minmax'])\n",
    "\n",
    "    print('-'*60)\n",
    "    print('R2_mlpr_std:', R2_mlpr_std)\n",
    "    print('R2_mlpr_minmax:', R2_mlpr_minmax)\n",
    "    print('R2_dtr_std:', R2_dtr_std)\n",
    "    print('R2_dtr_minmax:', R2_dtr_minmax)\n",
    "    print('-'*60)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(35, 5))\n",
    "    \n",
    "    # radiacao - MLPR - STD\n",
    "    ax.plot(df_week['hora'], df_week['determined_rad_mlpr_std'], color='#FF0000', label=f\"MLPR STD ({R2_mlpr_std:.4f})\")\n",
    "    # radiacao - MLPR - MINMAX\n",
    "    ax.plot(df_week['hora'], df_week['determined_rad_mlpr_minmax'], color='#C40000', label=f\"MLPR MINMAX ({R2_mlpr_minmax:.4f})\")\n",
    "    # radiacao - DTR - STD\n",
    "    ax.plot(df_week['hora'], df_week['determined_rad_dtr_std'], color='#FF9B00', label=f\"DTR STD ({R2_dtr_std:.4f})\")\n",
    "    # radiacao - DTR - MINMAX\n",
    "    ax.plot(df_week['hora'], df_week['determined_rad_dtr_minmax'], color='#CE7D00', label=f\"DTR MINMAX ({R2_dtr_minmax:.4f})\")\n",
    "\n",
    "    # radiacao measure\n",
    "    ax.plot(df_week['hora'], df_week['radiacao'], color='#000000', label='Irradiacao medida')\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=14)\n",
    "    ax.set_xlabel('hora', fontsize=14)\n",
    "    ax.set_ylabel('Irradiacao (Kj/m2)', fontsize=14)\n",
    "    ax.set_title(f'{string_station} semana {day}/{month}/{year}', fontsize=14)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=14)\n",
    "\n",
    "    # Save as PDF\n",
    "    save_path = f'{local_save}/{string_station}_radiacao_semana_{day}_{month}_{year}.pdf'\n",
    "    if local_save is not None:\n",
    "        plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # Show\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_determined_radation_week('FOZ DO IGUACU', selected_stations, 14, 7, 2010, 'figures_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
